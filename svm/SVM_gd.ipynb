{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of Xtrain is (2000, 784)\n",
      "The shape of ytrain is (2000, 1)\n",
      "The shape of Xtest is (500, 784)\n",
      "The shape of ytest is (500, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time \n",
    "from sklearn.preprocessing import LabelBinarizer, StandardScaler\n",
    "\n",
    "class normalizer():\n",
    "    def __init__(self):\n",
    "        self.mean = 0\n",
    "        self.std = 0\n",
    "\n",
    "    def fit(self, X):\n",
    "        self.mean = np.mean(X, axis=0) # mean of each column vector\n",
    "        self.std = np.std(X, axis=0) # std of each column vector\n",
    "        self.std[self.std <= 1e-5] = 1\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "            feature normalization. Each row of X represents a point in R^d. \n",
    "            Substract by the mean of X and then divided by the std of X.\n",
    "        \"\"\"\n",
    "        return (X - self.mean)/self.std\n",
    "\n",
    "def gradient(X, y, c, lam):\n",
    "    \"\"\"\n",
    "        loss is \\sigma_i c_i^2 + lambda \\sigma_i max(0, 1-y^i np.dot(c, x^i)) \n",
    "        y has two classes -1 and 1.\n",
    "    \"\"\"\n",
    "    hinge_loss = 1 - y * np.dot(X, c) \n",
    "    hinge_loss[hinge_loss <= 1e-5] = 0 # hinge loss\n",
    "    grad = - lam * np.dot(y[hinge_loss != 0], X[hinge_loss !=0, :])\n",
    "    grad += 2 * np.concatenate(([0], c[1:]), axis=None)\n",
    "    return grad\n",
    "\n",
    "# Below is my old implementation of gradient computation, and it is slow.\n",
    "#def gradient(X, y, c, lam):\n",
    "#    hinge_loss = 1 - y * np.dot(X, c) \n",
    "#    hinge_loss[hinge_loss <= 1e-5] = 0 # hinge loss\n",
    "#    grad = np.zeros(len(c))\n",
    "#    for idx, h in enumerate(hinge_loss):\n",
    "#        if h == 0:\n",
    "#            dh = np.zeros(len(c))\n",
    "#        else:\n",
    "#            dh = - lam * (y[idx] * X[idx, :])\n",
    "#        grad += dh\n",
    "#    grad += 2 * np.concatenate(([0], c[1:]), axis=None)\n",
    "#    return grad\n",
    "\n",
    "def GD(X, y, epochs, lr, lam):\n",
    "    \"\"\"\n",
    "        Implement gradient descent.\n",
    "        X: extended data. \n",
    "        lr: learning rate.\n",
    "        lam: regularization parameter lambda\n",
    "        ------\n",
    "        Return\n",
    "        c: parameters of linear classifier.\n",
    "    \"\"\"\n",
    "    c = np.ones(X.shape[1])\n",
    "    # gradient descent\n",
    "    for epoch in range(epochs): \n",
    "        c = c - lr * gradient(X, y, c, lam)\n",
    "        #if (epoch+1 % 100) == 0:\n",
    "            #print(\"After {} epochs, cost is {}\".format(epoch, cost(X, y, c, lam)))\n",
    "    return c\n",
    "\n",
    "def accuracy(ypred, yreal):\n",
    "    return np.sum(ypred==yreal)/float(len(yreal))\n",
    "\n",
    "\n",
    "Xtrain = pd.read_csv(\"MNIST_X_train.csv\").values\n",
    "ytrain = pd.read_csv(\"MNIST_Y_train.csv\").values\n",
    "Xtest = pd.read_csv(\"MNIST_X_test.csv\").values\n",
    "ytest = pd.read_csv(\"MNIST_Y_test.csv\").values\n",
    "\n",
    "print(\"The shape of Xtrain is {}\".format(Xtrain.shape))\n",
    "print(\"The shape of ytrain is {}\".format(ytrain.shape))\n",
    "print(\"The shape of Xtest is {}\".format(Xtest.shape))\n",
    "print(\"The shape of ytest is {}\".format(ytest.shape))\n",
    "\n",
    "ytrain, ytest = ytrain.flatten(), ytest.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer(neg_label=-1)\n",
    "lb.fit(ytrain)\n",
    "ytrain_ohe = lb.transform(ytrain)\n",
    "ytest_ohe  = lb.transform(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training class 0 vs all is complete. The training accuracy is 98.65%\n",
      "Training class 1 vs all is complete. The training accuracy is 99.10%\n",
      "Training class 2 vs all is complete. The training accuracy is 98.35%\n",
      "Training class 3 vs all is complete. The training accuracy is 97.25%\n",
      "Training class 4 vs all is complete. The training accuracy is 98.90%\n",
      "Training class 5 vs all is complete. The training accuracy is 97.30%\n",
      "Training class 6 vs all is complete. The training accuracy is 98.45%\n",
      "Training class 7 vs all is complete. The training accuracy is 98.25%\n",
      "Training class 8 vs all is complete. The training accuracy is 96.25%\n",
      "Training class 9 vs all is complete. The training accuracy is 93.85%\n",
      "The accuracy of multiclass classification is 88.40%\n",
      "Takes 3.29 seconds.\n"
     ]
    }
   ],
   "source": [
    "# Feature scaling\n",
    "scaler = normalizer()\n",
    "scaler.fit(Xtrain)\n",
    "normalized_Xtrain = scaler.transform(Xtrain)\n",
    "normalized_Xtest = scaler.transform(Xtest)\n",
    "\n",
    "extended_normalized_Xtrain = np.concatenate((np.ones((Xtrain.shape[0],1)), normalized_Xtrain), axis=1)\n",
    "extended_normalized_Xtest = np.concatenate((np.ones((Xtest.shape[0],1)), normalized_Xtest), axis=1)\n",
    "\n",
    "epochs = 100\n",
    "lr = 0.03\n",
    "lam = 1/200 # lambda\n",
    "\n",
    "start = time.time()\n",
    "      \n",
    "preds = np.zeros((Xtest.shape[0], 10))\n",
    "# one vs all approach\n",
    "for i in range(10):\n",
    "    # Train class i vs rest\n",
    "    params = GD(extended_normalized_Xtrain, ytrain_ohe[:,i], epochs, lr, lam)\n",
    "    preds[:, i] = np.dot(extended_normalized_Xtest, params) # labels is going to be used for prediction on test data\n",
    "    pred_labels = np.dot(extended_normalized_Xtrain, params) \n",
    "    pred_labels[pred_labels<1e-5] = -1\n",
    "    pred_labels[pred_labels>=1e-5] = 1 # pred_labels are the labels predicted on training data\n",
    "    # compute training accuracy\n",
    "    score = accuracy(ytrain_ohe[:,i], pred_labels)\n",
    "    print(\"Training class {} vs all is complete. The training accuracy is {:.2f}%\".format(i, score*100))\n",
    "\n",
    "ypred = np.argmax(preds, axis=1)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "score = accuracy(ytest, ypred)\n",
    "print(\"The accuracy of multiclass classification is {:.2f}%\".format(score*100))\n",
    "print(\"Takes {:.2f} seconds.\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training class 0 vs class 1 is complete. The training accuracy is 100.00%\n",
      "Training class 0 vs class 2 is complete. The training accuracy is 99.05%\n",
      "Training class 0 vs class 3 is complete. The training accuracy is 98.05%\n",
      "Training class 0 vs class 4 is complete. The training accuracy is 99.75%\n",
      "Training class 0 vs class 5 is complete. The training accuracy is 99.23%\n",
      "Training class 0 vs class 6 is complete. The training accuracy is 100.00%\n",
      "Training class 0 vs class 7 is complete. The training accuracy is 99.76%\n",
      "Training class 0 vs class 8 is complete. The training accuracy is 98.68%\n",
      "Training class 0 vs class 9 is complete. The training accuracy is 99.49%\n",
      "Training class 1 vs class 2 is complete. The training accuracy is 98.00%\n",
      "Training class 1 vs class 3 is complete. The training accuracy is 97.05%\n",
      "Training class 1 vs class 4 is complete. The training accuracy is 99.54%\n",
      "Training class 1 vs class 5 is complete. The training accuracy is 98.80%\n",
      "Training class 1 vs class 6 is complete. The training accuracy is 99.77%\n",
      "Training class 1 vs class 7 is complete. The training accuracy is 99.11%\n",
      "Training class 1 vs class 8 is complete. The training accuracy is 97.30%\n",
      "Training class 1 vs class 9 is complete. The training accuracy is 99.52%\n",
      "Training class 2 vs class 3 is complete. The training accuracy is 97.12%\n",
      "Training class 2 vs class 4 is complete. The training accuracy is 99.03%\n",
      "Training class 2 vs class 5 is complete. The training accuracy is 99.49%\n",
      "Training class 2 vs class 6 is complete. The training accuracy is 99.26%\n",
      "Training class 2 vs class 7 is complete. The training accuracy is 99.76%\n",
      "Training class 2 vs class 8 is complete. The training accuracy is 97.66%\n",
      "Training class 2 vs class 9 is complete. The training accuracy is 99.75%\n",
      "Training class 3 vs class 4 is complete. The training accuracy is 99.50%\n",
      "Training class 3 vs class 5 is complete. The training accuracy is 97.15%\n",
      "Training class 3 vs class 6 is complete. The training accuracy is 99.75%\n",
      "Training class 3 vs class 7 is complete. The training accuracy is 99.28%\n",
      "Training class 3 vs class 8 is complete. The training accuracy is 96.53%\n",
      "Training class 3 vs class 9 is complete. The training accuracy is 98.97%\n",
      "Training class 4 vs class 5 is complete. The training accuracy is 99.47%\n",
      "Training class 4 vs class 6 is complete. The training accuracy is 99.49%\n",
      "Training class 4 vs class 7 is complete. The training accuracy is 98.05%\n",
      "Training class 4 vs class 8 is complete. The training accuracy is 98.37%\n",
      "Training class 4 vs class 9 is complete. The training accuracy is 96.34%\n",
      "Training class 5 vs class 6 is complete. The training accuracy is 99.73%\n",
      "Training class 5 vs class 7 is complete. The training accuracy is 99.24%\n",
      "Training class 5 vs class 8 is complete. The training accuracy is 95.47%\n",
      "Training class 5 vs class 9 is complete. The training accuracy is 98.91%\n",
      "Training class 6 vs class 7 is complete. The training accuracy is 99.75%\n",
      "Training class 6 vs class 8 is complete. The training accuracy is 98.08%\n",
      "Training class 6 vs class 9 is complete. The training accuracy is 99.73%\n",
      "Training class 7 vs class 8 is complete. The training accuracy is 99.22%\n",
      "Training class 7 vs class 9 is complete. The training accuracy is 96.21%\n",
      "Training class 8 vs class 9 is complete. The training accuracy is 98.87%\n",
      "The accuracy of multiclass classification is 89.60%\n",
      "Takes 2.33 seconds.\n"
     ]
    }
   ],
   "source": [
    "# A more concise version of one vs one classification\n",
    "# Feature scaling\n",
    "scaler = normalizer()\n",
    "scaler.fit(Xtrain)\n",
    "normalized_Xtrain = scaler.transform(Xtrain)\n",
    "normalized_Xtest = scaler.transform(Xtest)\n",
    "\n",
    "extended_normalized_Xtrain = np.concatenate((np.ones((Xtrain.shape[0],1)), normalized_Xtrain), axis=1)\n",
    "extended_normalized_Xtest = np.concatenate((np.ones((Xtest.shape[0],1)), normalized_Xtest), axis=1)\n",
    "\n",
    "epochs = 100\n",
    "lr = 0.03\n",
    "lam = 1/200 # lambda\n",
    "\n",
    "start = time.time()\n",
    "labels = np.zeros((Xtest.shape[0], 10))\n",
    "# one vs one approach\n",
    "for i in range(9):\n",
    "    for j in range(10):\n",
    "        if j > i:\n",
    "            data = extended_normalized_Xtrain[(ytrain_ohe[:, i]==1)+(ytrain_ohe[:, j]==1)]\n",
    "            target = ytrain_ohe[:,i][(ytrain_ohe[:, i]==1)+(ytrain_ohe[:, j]==1)]\n",
    "            # Train class i vs class j\n",
    "            params = GD(data, target, epochs, lr, lam)\n",
    "            \n",
    "            labels_training_sets = np.dot(data, params) \n",
    "            labels_training_sets[labels_training_sets >=1e-5] = 1\n",
    "            labels_training_sets[labels_training_sets < 1e-5] = -1 # labels predicted on training sets\n",
    "            # compute training accuracy\n",
    "            score = accuracy(target, labels_training_sets)\n",
    "            print(\"Training class {} vs class {} is complete. The training accuracy is {:.2f}%\".format(i,j,score*100))\n",
    "            \n",
    "            pred = np.dot(extended_normalized_Xtest, params)\n",
    "            labels[:, i][pred>=1e-5] += 1\n",
    "            labels[:, j][pred<1e-5] += 1\n",
    "\n",
    "ypred = np.argmax(labels, axis=1)\n",
    "end = time.time()\n",
    "\n",
    "score = accuracy(ytest, ypred)\n",
    "print(\"The accuracy of multiclass classification is {:.2f}%\".format(score*100))\n",
    "print(\"Takes {:.2f} seconds.\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
